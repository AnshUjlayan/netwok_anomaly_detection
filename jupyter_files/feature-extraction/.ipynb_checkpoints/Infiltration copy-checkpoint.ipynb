{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14425df2",
   "metadata": {},
   "source": [
    "# Class 4 - Infiltration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a064e2a9",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05669a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import (chi2, f_classif, mutual_info_classif, RFE, SelectFromModel, SelectKBest)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, f1_score, precision_score, recall_score)\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5effd0b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12639793, 71)\n"
     ]
    }
   ],
   "source": [
    "# Define the list of file names\n",
    "file_names = [\n",
    "    \"../../train/02-14-2018_clean.csv\",\n",
    "    \"../../train/02-15-2018_clean.csv\",\n",
    "    \"../../train/02-16-2018_clean.csv\",\n",
    "    \"../../train/02-20-2018_clean.csv\",\n",
    "    \"../../train/02-21-2018_clean.csv\",\n",
    "    \"../../train/02-22-2018_clean.csv\",\n",
    "    \"../../train/02-23-2018_clean.csv\",\n",
    "    \"../../train/02-28-2018_clean.csv\",\n",
    "    \"../../train/03-01-2018_clean.csv\",\n",
    "    \"../../train/03-02-2018_clean.csv\"\n",
    "]\n",
    "\n",
    "# Initialize an empty list to store the DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through the file names and read each file as a DataFrame\n",
    "for file_name in file_names:\n",
    "    df = pd.read_csv(file_name)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate the DataFrames into a single DataFrame\n",
    "data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Print the shape of the combined DataFrame\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e7f381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your DataFrame is named 'data'\n",
    "instances_label_0 = data.query(\"Label == 0\").sample(n=103499)\n",
    "instances_label_1 = data.query(\"Label == 4\").sample(n=103499)\n",
    "instances_label_1['Label'] = 1\n",
    "\n",
    "# Combine the two DataFrames\n",
    "combined_df = pd.concat([instances_label_0, instances_label_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1556295",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_instances_label_0 = data.query(\"Label == 0\").drop(instances_label_0.index).sample(n=25874)\n",
    "test_instances_label_1 = data.query(\"Label == 4\").drop(instances_label_1.index).sample(n=25874)\n",
    "test_instances_label_1['Label'] = 1\n",
    "\n",
    "# Combine the two DataFrames\n",
    "test_combined_df = pd.concat([test_instances_label_0, test_instances_label_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb37ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = combined_df.drop(columns='Label')\n",
    "y_train = combined_df['Label']\n",
    "\n",
    "X_test = test_combined_df.drop(columns='Label')\n",
    "y_test = test_combined_df['Label']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cb0faf",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec320a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Information Gain (IG)\n",
    "selector_ig = SelectKBest(score_func=mutual_info_classif, k=15)\n",
    "X_train_ig = selector_ig.fit_transform(X_train, y_train)\n",
    "X_test_ig = selector_ig.transform(X_test)\n",
    "selected_columns_ig = X_train.columns[selector_ig.get_support()]\n",
    "\n",
    "# 2. Chi-Square (CS)\n",
    "selector_cs = SelectKBest(score_func=chi2, k=15)\n",
    "X_train_cs = selector_cs.fit_transform(X_train_scaled, y_train)\n",
    "X_test_cs = selector_cs.transform(X_test_scaled)\n",
    "selected_columns_cs = X_train.columns[selector_cs.get_support()]\n",
    "\n",
    "# 3. Gain Ratio (GR)\n",
    "def gain_ratio(X, y):\n",
    "    mi = mutual_info_classif(X, y)\n",
    "    H_y = -np.sum(np.unique(y, return_counts=True)[1] / len(y) * np.log2(np.unique(y, return_counts=True)[1] / len(y)))\n",
    "    return mi / H_y\n",
    "\n",
    "selector_gr = SelectKBest(score_func=gain_ratio, k=15)\n",
    "X_train_gr = selector_gr.fit_transform(X_train, y_train)\n",
    "X_test_gr = selector_gr.transform(X_test)\n",
    "selected_columns_gr = X_train.columns[selector_gr.get_support()]\n",
    "\n",
    "# 4. Recursive Feature Elimination (RFE)\n",
    "logreg = LogisticRegression()\n",
    "selector_rfe = RFE(logreg, n_features_to_select=15)\n",
    "X_train_rfe = selector_rfe.fit_transform(X_train, y_train)\n",
    "X_test_rfe = selector_rfe.transform(X_test)\n",
    "selected_columns_rfe = X_train.columns[selector_rfe.get_support()]\n",
    "\n",
    "# 5. SelectKBest\n",
    "selector_skb = SelectKBest(score_func=f_classif, k=15)\n",
    "X_train_skb = selector_skb.fit_transform(X_train, y_train)\n",
    "X_test_skb = selector_skb.transform(X_test)\n",
    "selected_columns_skb = X_train.columns[selector_skb.get_support()]\n",
    "\n",
    "# 6. Feature Importance using Tree-based Models\n",
    "rfc = RandomForestClassifier()\n",
    "selector_rf = SelectFromModel(rfc, max_features=15)\n",
    "X_train_rf = selector_rf.fit_transform(X_train, y_train)\n",
    "X_test_rf = selector_rf.transform(X_test)\n",
    "selected_columns_rf = X_train.columns[selector_rf.get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3559afc9",
   "metadata": {},
   "source": [
    "## Train XGBoost on each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac954591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate XGBoost model on selected columns from IG\n",
    "xgb_ig = XGBClassifier()\n",
    "xgb_ig.fit(X_train_ig, y_train)\n",
    "y_pred_ig = xgb_ig.predict(X_test_ig)\n",
    "\n",
    "# Train and evaluate XGBoost model on selected columns from CS\n",
    "xgb_cs = XGBClassifier()\n",
    "xgb_cs.fit(X_train_cs, y_train)\n",
    "y_pred_cs = xgb_cs.predict(X_test_cs)\n",
    "\n",
    "# Train and evaluate XGBoost model on selected columns from GR\n",
    "xgb_gr = XGBClassifier()\n",
    "xgb_gr.fit(X_train_gr, y_train)\n",
    "y_pred_gr = xgb_gr.predict(X_test_gr)\n",
    "\n",
    "# Train and evaluate XGBoost model on selected columns from RFE\n",
    "xgb_rfe = XGBClassifier()\n",
    "xgb_rfe.fit(X_train_rfe, y_train)\n",
    "y_pred_rfe = xgb_rfe.predict(X_test_rfe)\n",
    "\n",
    "# Train and evaluate XGBoost model on selected columns from SKB\n",
    "xgb_skb = XGBClassifier()\n",
    "xgb_skb.fit(X_train_skb, y_train)\n",
    "y_pred_skb = xgb_skb.predict(X_test_skb)\n",
    "\n",
    "# Train and evaluate XGBoost model on selected columns from RF\n",
    "xgb_rf = XGBClassifier()\n",
    "xgb_rf.fit(X_train_rf, y_train)\n",
    "y_pred_rf = xgb_rf.predict(X_test_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db15ec4",
   "metadata": {},
   "source": [
    "## Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3619cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics for each technique\n",
    "def calculate_metrics(y_test, y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "metrics_dict = {\n",
    "    'IG': calculate_metrics(y_test, y_pred_ig),\n",
    "    'CS': calculate_metrics(y_test, y_pred_cs),\n",
    "    'GR': calculate_metrics(y_test, y_pred_gr),\n",
    "    'RFE': calculate_metrics(y_test, y_pred_rfe),\n",
    "    'SKB': calculate_metrics(y_test, y_pred_skb),\n",
    "    'RF': calculate_metrics(y_test, y_pred_rf)\n",
    "}\n",
    "\n",
    "# Print the metrics for each technique\n",
    "for technique, metrics in metrics_dict.items():\n",
    "    accuracy, precision, recall, f1 = metrics\n",
    "    print(f\"Metrics for {technique}:\")\n",
    "    print(f\"  Accuracy: {accuracy}\")\n",
    "    print(f\"  Precision: {precision}\")\n",
    "    print(f\"  Recall: {recall}\")\n",
    "    print(f\"  F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bca033d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Define the models and their predictions\n",
    "models = {\n",
    "    \"Information Gain\": y_pred_ig,\n",
    "    \"Chi-Square\": y_pred_cs,\n",
    "    \"Gain Ratio\": y_pred_gr,\n",
    "    \"Recursive Feature Elimination\": y_pred_rfe,\n",
    "    \"SelectKBest\": y_pred_skb,\n",
    "    \"Feature Importance using Tree-based Models\": y_pred_rf,\n",
    "}\n",
    "\n",
    "# Compute confusion matrices and plot heatmaps\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "for i, (name, y_pred) in enumerate(models.items()):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"YlGnBu\", ax=axes[i])\n",
    "    axes[i].set_title(name)\n",
    "    axes[i].set_xlabel(\"Predicted\")\n",
    "    axes[i].set_ylabel(\"Actual\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e19b592",
   "metadata": {},
   "source": [
    "## Features selected by each technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8835ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define the selected columns by each technique\n",
    "selected_columns = {\n",
    "    \"Information Gain\": selected_columns_ig,\n",
    "    \"Chi-Square\": selected_columns_cs,\n",
    "    \"Gain Ratio\": selected_columns_gr,\n",
    "    \"Recursive Feature Elimination\": selected_columns_rfe,\n",
    "    \"SelectKBest\": selected_columns_skb,\n",
    "    \"Feature Importance using Tree-based Models\": selected_columns_rf,\n",
    "}\n",
    "\n",
    "# Print the selected features\n",
    "for name, columns in selected_columns.items():\n",
    "    print(f\"{name}:\")\n",
    "    for column in columns:\n",
    "        print(f\"  - {column}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1e62a8",
   "metadata": {},
   "source": [
    "## Final selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10d3c903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Features (Information Gain, Gain Ratio & Chi-Square Models:\n",
      "  - Subflow Fwd Byts\n",
      "  - Bwd Pkt Len Min\n",
      "  - Fwd Header Len\n",
      "  - Fwd IAT Max\n",
      "  - Fwd IAT Tot\n",
      "  - Init Bwd Win Byts\n",
      "  - TotLen Fwd Pkts\n",
      "  - Fwd PSH Flags\n",
      "  - Init Fwd Win Byts\n",
      "  - Time\n",
      "  - ACK Flag Cnt\n",
      "  - Dst Port\n",
      "  - Bwd IAT Tot\n",
      "  - SYN Flag Cnt\n",
      "  - Fwd Pkt Len Max\n",
      "  - Protocol\n",
      "  - Fwd IAT Mean\n"
     ]
    }
   ],
   "source": [
    "# Find the union of the two sets of selected features\n",
    "combined_features = set(selected_columns_ig).union(selected_columns_cs).union(selected_columns_gr)\n",
    "\n",
    "# Print the combined features\n",
    "print(\"Combined Features (Information Gain, Gain Ratio & Chi-Square Models:\")\n",
    "for feature in combined_features:\n",
    "    print(f\"  - {feature}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
