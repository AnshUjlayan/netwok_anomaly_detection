{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14425df2",
   "metadata": {},
   "source": [
    "# Class 4 - Infiltration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a064e2a9",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05669a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import (chi2, f_classif, mutual_info_classif, RFE, SelectFromModel, SelectKBest)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, f1_score, precision_score, recall_score)\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5effd0b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7t/6qs561wj79vg29_cgy74ngwh0000gn/T/ipykernel_2175/4175458816.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Loop through the file names and read each file as a DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1251\u001b[0m             \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1253\u001b[0;31m                 \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1254\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_extension_array_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_extension_array_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1430\u001b[0m     \"\"\"\n\u001b[1;32m   1431\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0man\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0mextension\u001b[0m \u001b[0marray\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the list of file names\n",
    "file_names = [\n",
    "    \"../../train/02-14-2018_clean.csv\",\n",
    "    \"../../train/02-15-2018_clean.csv\",\n",
    "    \"../../train/02-16-2018_clean.csv\",\n",
    "    \"../../train/02-20-2018_clean.csv\",\n",
    "    \"../../train/02-21-2018_clean.csv\",\n",
    "    \"../../train/02-22-2018_clean.csv\",\n",
    "    \"../../train/02-23-2018_clean.csv\",\n",
    "    \"../../train/02-28-2018_clean.csv\",\n",
    "    \"../../train/03-01-2018_clean.csv\",\n",
    "    \"../../train/03-02-2018_clean.csv\"\n",
    "]\n",
    "\n",
    "# Initialize an empty list to store the DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through the file names and read each file as a DataFrame\n",
    "for file_name in file_names:\n",
    "    df = pd.read_csv(file_name)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate the DataFrames into a single DataFrame\n",
    "data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Print the shape of the combined DataFrame\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7f381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your DataFrame is named 'data'\n",
    "instances_label_0 = data.query(\"Label == 0\").sample(n=103499)\n",
    "instances_label_1 = data.query(\"Label == 4\").sample(n=103499)\n",
    "instances_label_1['Label'] = 1\n",
    "\n",
    "# Combine the two DataFrames\n",
    "combined_df = pd.concat([instances_label_0, instances_label_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1556295",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_instances_label_0 = data.query(\"Label == 0\").drop(instances_label_0.index).sample(n=25874)\n",
    "test_instances_label_1 = data.query(\"Label == 4\").drop(instances_label_1.index).sample(n=25874)\n",
    "test_instances_label_1['Label'] = 1\n",
    "\n",
    "# Combine the two DataFrames\n",
    "test_combined_df = pd.concat([test_instances_label_0, test_instances_label_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb37ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = combined_df.drop(columns='Label')\n",
    "y_train = combined_df['Label']\n",
    "\n",
    "X_test = test_combined_df.drop(columns='Label')\n",
    "y_test = test_combined_df['Label']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cb0faf",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec320a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Information Gain (IG)\n",
    "selector_ig = SelectKBest(score_func=mutual_info_classif, k=10)\n",
    "X_train_ig = selector_ig.fit_transform(X_train, y_train)\n",
    "X_test_ig = selector_ig.transform(X_test)\n",
    "selected_columns_ig = X_train.columns[selector_ig.get_support()]\n",
    "\n",
    "# 2. Chi-Square (CS)\n",
    "selector_cs = SelectKBest(score_func=chi2, k=10)\n",
    "X_train_cs = selector_cs.fit_transform(X_train_scaled, y_train)\n",
    "X_test_cs = selector_cs.transform(X_test_scaled)\n",
    "selected_columns_cs = X_train.columns[selector_cs.get_support()]\n",
    "\n",
    "# 3. Gain Ratio (GR)\n",
    "def gain_ratio(X, y):\n",
    "    mi = mutual_info_classif(X, y)\n",
    "    H_y = -np.sum(np.unique(y, return_counts=True)[1] / len(y) * np.log2(np.unique(y, return_counts=True)[1] / len(y)))\n",
    "    return mi / H_y\n",
    "\n",
    "selector_gr = SelectKBest(score_func=gain_ratio, k=10)\n",
    "X_train_gr = selector_gr.fit_transform(X_train, y_train)\n",
    "X_test_gr = selector_gr.transform(X_test)\n",
    "selected_columns_gr = X_train.columns[selector_gr.get_support()]\n",
    "\n",
    "# 4. Recursive Feature Elimination (RFE)\n",
    "logreg = LogisticRegression()\n",
    "selector_rfe = RFE(logreg, n_features_to_select=10)\n",
    "X_train_rfe = selector_rfe.fit_transform(X_train, y_train)\n",
    "X_test_rfe = selector_rfe.transform(X_test)\n",
    "selected_columns_rfe = X_train.columns[selector_rfe.get_support()]\n",
    "\n",
    "# 5. SelectKBest\n",
    "selector_skb = SelectKBest(score_func=f_classif, k=10)\n",
    "X_train_skb = selector_skb.fit_transform(X_train, y_train)\n",
    "X_test_skb = selector_skb.transform(X_test)\n",
    "selected_columns_skb = X_train.columns[selector_skb.get_support()]\n",
    "\n",
    "# 6. Feature Importance using Tree-based Models\n",
    "rfc = RandomForestClassifier()\n",
    "selector_rf = SelectFromModel(rfc, max_features=10)\n",
    "X_train_rf = selector_rf.fit_transform(X_train, y_train)\n",
    "X_test_rf = selector_rf.transform(X_test)\n",
    "selected_columns_rf = X_train.columns[selector_rf.get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3559afc9",
   "metadata": {},
   "source": [
    "## Train XGBoost on each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac954591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate XGBoost model on selected columns from IG\n",
    "xgb_ig = XGBClassifier()\n",
    "xgb_ig.fit(X_train_ig, y_train)\n",
    "y_pred_ig = xgb_ig.predict(X_test_ig)\n",
    "\n",
    "# Train and evaluate XGBoost model on selected columns from CS\n",
    "xgb_cs = XGBClassifier()\n",
    "xgb_cs.fit(X_train_cs, y_train)\n",
    "y_pred_cs = xgb_cs.predict(X_test_cs)\n",
    "\n",
    "# Train and evaluate XGBoost model on selected columns from GR\n",
    "xgb_gr = XGBClassifier()\n",
    "xgb_gr.fit(X_train_gr, y_train)\n",
    "y_pred_gr = xgb_gr.predict(X_test_gr)\n",
    "\n",
    "# Train and evaluate XGBoost model on selected columns from RFE\n",
    "xgb_rfe = XGBClassifier()\n",
    "xgb_rfe.fit(X_train_rfe, y_train)\n",
    "y_pred_rfe = xgb_rfe.predict(X_test_rfe)\n",
    "\n",
    "# Train and evaluate XGBoost model on selected columns from SKB\n",
    "xgb_skb = XGBClassifier()\n",
    "xgb_skb.fit(X_train_skb, y_train)\n",
    "y_pred_skb = xgb_skb.predict(X_test_skb)\n",
    "\n",
    "# Train and evaluate XGBoost model on selected columns from RF\n",
    "xgb_rf = XGBClassifier()\n",
    "xgb_rf.fit(X_train_rf, y_train)\n",
    "y_pred_rf = xgb_rf.predict(X_test_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db15ec4",
   "metadata": {},
   "source": [
    "## Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3619cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics for each technique\n",
    "def calculate_metrics(y_test, y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "metrics_dict = {\n",
    "    'IG': calculate_metrics(y_test, y_pred_ig),\n",
    "    'CS': calculate_metrics(y_test, y_pred_cs),\n",
    "    'GR': calculate_metrics(y_test, y_pred_gr),\n",
    "    'RFE': calculate_metrics(y_test, y_pred_rfe),\n",
    "    'SKB': calculate_metrics(y_test, y_pred_skb),\n",
    "    'RF': calculate_metrics(y_test, y_pred_rf)\n",
    "}\n",
    "\n",
    "# Print the metrics for each technique\n",
    "for technique, metrics in metrics_dict.items():\n",
    "    accuracy, precision, recall, f1 = metrics\n",
    "    print(f\"Metrics for {technique}:\")\n",
    "    print(f\"  Accuracy: {accuracy}\")\n",
    "    print(f\"  Precision: {precision}\")\n",
    "    print(f\"  Recall: {recall}\")\n",
    "    print(f\"  F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bca033d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Define the models and their predictions\n",
    "models = {\n",
    "    \"Information Gain\": y_pred_ig,\n",
    "    \"Chi-Square\": y_pred_cs,\n",
    "    \"Gain Ratio\": y_pred_gr,\n",
    "    \"Recursive Feature Elimination\": y_pred_rfe,\n",
    "    \"SelectKBest\": y_pred_skb,\n",
    "    \"Feature Importance using Tree-based Models\": y_pred_rf,\n",
    "}\n",
    "\n",
    "# Compute confusion matrices and plot heatmaps\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "for i, (name, y_pred) in enumerate(models.items()):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"YlGnBu\", ax=axes[i])\n",
    "    axes[i].set_title(name)\n",
    "    axes[i].set_xlabel(\"Predicted\")\n",
    "    axes[i].set_ylabel(\"Actual\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e19b592",
   "metadata": {},
   "source": [
    "## Features selected by each technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8835ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define the selected columns by each technique\n",
    "selected_columns = {\n",
    "    \"Information Gain\": selected_columns_ig,\n",
    "    \"Chi-Square\": selected_columns_cs,\n",
    "    \"Gain Ratio\": selected_columns_gr,\n",
    "    \"Recursive Feature Elimination\": selected_columns_rfe,\n",
    "    \"SelectKBest\": selected_columns_skb,\n",
    "    \"Feature Importance using Tree-based Models\": selected_columns_rf,\n",
    "}\n",
    "\n",
    "# Print the selected features\n",
    "for name, columns in selected_columns.items():\n",
    "    print(f\"{name}:\")\n",
    "    for column in columns:\n",
    "        print(f\"  - {column}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1e62a8",
   "metadata": {},
   "source": [
    "## Final selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10d3c903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Features (Information Gain, Gain Ratio & Chi-Square Models:\n",
      "  - Subflow Fwd Byts\n",
      "  - Bwd Pkt Len Min\n",
      "  - Fwd Header Len\n",
      "  - Fwd IAT Max\n",
      "  - Fwd IAT Tot\n",
      "  - Init Bwd Win Byts\n",
      "  - TotLen Fwd Pkts\n",
      "  - Fwd PSH Flags\n",
      "  - Init Fwd Win Byts\n",
      "  - Time\n",
      "  - ACK Flag Cnt\n",
      "  - Dst Port\n",
      "  - Bwd IAT Tot\n",
      "  - SYN Flag Cnt\n",
      "  - Fwd Pkt Len Max\n",
      "  - Protocol\n",
      "  - Fwd IAT Mean\n"
     ]
    }
   ],
   "source": [
    "# Find the union of the two sets of selected features\n",
    "combined_features = set(selected_columns_ig).union(selected_columns_cs).union(selected_columns_gr)\n",
    "\n",
    "# Print the combined features\n",
    "print(\"Combined Features (Information Gain, Gain Ratio & Chi-Square Models:\")\n",
    "for feature in combined_features:\n",
    "    print(f\"  - {feature}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
